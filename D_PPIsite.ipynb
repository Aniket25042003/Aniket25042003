{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1pE9aCUyf+oLLyUwl9M7p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aniket25042003/Aniket25042003/blob/main/D_PPIsite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Physical_properties.py"
      ],
      "metadata": {
        "id": "eFYTMF7Rs5VW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaGIQG6Ysn2K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def F_Physical_properties(protein, Feature_path):\n",
        "    pro_name_dir = protein # Assigns the directory path of protein file\n",
        "    Physical_properties_dir = Feature_path # Assigns the directory path of the physical properties file\n",
        "\n",
        "    pro_name_file = open(pro_name_dir) # Opens pro_name_dir (Protein file) for reading\n",
        "    content_name = pro_name_file.readline() # Reads the first line of pro_name_file (Protein file)\n",
        "    content_Physical_properties = pro_name_file.readline().strip() # Reads the second line of pro_name_file (Protein file) and removes whitespace characters\n",
        "    Physical_properties_file = open(Physical_properties_dir, 'w') # Opens Physical_properties_dir (Physical Property File) for writing\n",
        "    for i in range(len(content_Physical_properties)): # Iterates over the characters in content_Physical_properties\n",
        "        if content_Physical_properties[i] == 'I': # If character is \"I\"\n",
        "            P_C = '4.19 0.19 4.00 1.80 6.04 0.30 0.45' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'V': # If character is \"V\"\n",
        "            P_C = '3.67 0.14 3.00 1.22 6.02 0.27 0.49' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'L': # If character is \"L\"\n",
        "            P_C = '2.59 0.19 4.00 1.70 6.04 0.39 0.31' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'F': # If character is \"F\"\n",
        "            P_C = '2.94 0.29 5.89 1.79 5.67 0.30 0.38' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'C': # If character is \"C\"\n",
        "            P_C = '1.77 0.13 2.43 1.54 6.35 0.17 0.41' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'M': # If character is \"M\"\n",
        "            P_C = '2.35 0.22 4.43 1.23 5.71 0.38 0.32' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'A': # If character is \"A\"\n",
        "            P_C = '1.28 0.05 1.00 0.31 6.11 0.42 0.23' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'G': # If character is \"G\"\n",
        "            P_C = '0.00 0.00 0.00 0.00 6.07 0.13 0.15' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'T': # If character is \"T\"\n",
        "            P_C = '3.03 0.11 2.60 0.26 5.60 0.21 0.36' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'W': # If character is \"W\"\n",
        "            P_C = '3.21 0.41 8.08 2.25 5.94 0.32 0.42' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'S': # If character is \"S\"\n",
        "            P_C = '1.31 0.06 1.60 -0.04 5.70 0.20 0.28' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'Y': # If character is \"Y\"\n",
        "            P_C = '2.94 0.30 6.47 0.96 5.66 0.25 0.41' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'P': # If character is \"P\"\n",
        "            P_C = '2.67 0.00 2.72 0.72 6.80 0.13 0.34' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'H': # If character is \"H\"\n",
        "            P_C = '2.99 0.23 4.66 0.13 7.69 0.27 0.30' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'E': # If character is \"E\"\n",
        "            P_C = '1.56 0.15 3.78 -0.64 3.09 0.42 0.21' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'Q': # If character is \"Q\"\n",
        "            P_C = '1.56 0.18 3.95 -0.22 5.65 0.36 0.25' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'D': # If character is \"D\"\n",
        "            P_C = '1.60 0.11 2.78 -0.77 2.95 0.25 0.20' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'N': # If character is \"N\"\n",
        "            P_C = '1.60 0.13 2.95 -0.60 6.52 0.21 0.22' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'K': # If character is \"K\"\n",
        "            P_C = '1.89 0.22 4.77 -0.99 9.99 0.32 0.27' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "        elif content_Physical_properties[i] == 'R': # If character is \"R\"\n",
        "            P_C = '2.34 0.29 6.13 -1.01 10.74 0.36 0.25' # Assigns the given P_C values\n",
        "            Physical_properties_file.writelines(str(P_C) + '\\n') # Wrties P_C values to the physical_properties_file (Physical Properties File) and appends a newline at the end\n",
        "\n",
        "    Physical_properties_file.close() # Closes the Physical_properties_file\n",
        "\n",
        "\n",
        "    read_file = open(Feature_path) # Opens Feature_path for reading\n",
        "    write_file = open(Feature_path+\".pp\", \"w\") # Opens Feature_path for writing and appends the original Feature_path with .pp\n",
        "    while True:\n",
        "        content = read_file.readline() # Reads the file line by line\n",
        "        if content == '': # If empty string  is encountered, the loop breaks\n",
        "            break\n",
        "        list = [] # Creates a list\n",
        "        for index in range(len(content)): # Runs for each line of content\n",
        "            if content[index] == ' ': # If there is a space character\n",
        "                list.append(index) # Append its index to the list\n",
        "\n",
        "        # Thr line is then split into seven parts based on the indices of the space characters\n",
        "        a = content[:list[0]]\n",
        "        b = content[list[0] + 1: list[1]]\n",
        "        c = content[list[1] + 1: list[2]]\n",
        "        d = content[list[2] + 1: list[3]]\n",
        "        e = content[list[3] + 1: list[4]]\n",
        "        f = content[list[4] + 1: list[5]]\n",
        "        g = content[list[5] + 1:]\n",
        "\n",
        "        # Converts the variables to floating-point numbers\n",
        "        a = float(a)\n",
        "        b = float(b)\n",
        "        c = float(c)\n",
        "        d = float(d)\n",
        "        e = float(e)\n",
        "        f = float(f)\n",
        "        g = float(g)\n",
        "\n",
        "        # Normalizes each variable by adding 1.01 and dividing by (10.74 + 1.01) to get score between 0 and 1\n",
        "        a = (a + 1.01) / (10.47 + 1.01)\n",
        "        b = (b + 1.01) / (10.74 + 1.01)\n",
        "        c = (c + 1.01) / (10.74 + 1.01)\n",
        "        d = (d + 1.01) / (10.74 + 1.01)\n",
        "        e = (e + 1.01) / (10.74 + 1.01)\n",
        "        f = (f + 1.01) / (10.74 + 1.01)\n",
        "        g = (g + 1.01) / (10.74 + 1.01)\n",
        "\n",
        "        # Rounds each variable to 3 decimal places\n",
        "        a = round(a, 3)\n",
        "        b = round(b, 3)\n",
        "        c = round(c, 3)\n",
        "        d = round(d, 3)\n",
        "        e = round(e, 3)\n",
        "        f = round(f, 3)\n",
        "        g = round(g, 3)\n",
        "\n",
        "        # Writes the variables to write_file as strings, seperates them by spaces and add a new line at the end\n",
        "        write_file.writelines(\n",
        "            str(a) + ' ' + str(b) + ' ' + str(c) + ' ' + str(d) + ' ' + str(e) + ' ' + str(f) + ' ' + str(g) + '\\n')\n",
        "    write_file.close() # Closes write_file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What & Why : It reads a protein sequence from a file and generates a physical properties file based on the sequence. It reads a feature file, normalizes the values, rounds them, and writes the normalized values to a new file."
      ],
      "metadata": {
        "id": "XrV9AkZxtyVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "position_information.py"
      ],
      "metadata": {
        "id": "IB8OxWiotA4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# F_position function processes protein and feature data and generates a position file\n",
        "def F_position(Protein_path, Feature_path):\n",
        "    pro_name_dir = Protein_path # Assigns directory path of the protein file\n",
        "    position_dir = Feature_path # Assigns directory path of the feature file\n",
        "\n",
        "\n",
        "    pro_name_file = open(pro_name_dir) # Opens pro_name_dir file (Protein file)\n",
        "    content_name = pro_name_file.readline() # # Reads first line from the pro_name_file (Protein file)\n",
        "    content_position = pro_name_file.readline().strip() # # Reads second line from the pro_name_file (Protein file) and removes whitespace characters\n",
        "    pro_name_file.close() # Closes pro_name_file (Protein file)\n",
        "    position_file = open(position_dir, 'w') # Opens position_dir (Feature file) for writing\n",
        "    for position in range(1,len(content_position)+1): # Interates from 1 to the length of content_position (Number of characters in content_position) + 1\n",
        "        position_score = position/len(content_position) # Calculates position_score by dividing position with content_position\n",
        "        position_score = round(position_score,3) # Rounds the position_score to 3 decimal places\n",
        "        position_file.writelines(str(position_score)+'\\n') # Writes the position_score to the file and appends a newline after each score\n",
        "\n",
        "    pro_name_file.close() # Closes pro_name_file\n",
        "\n",
        "# The code reads protein and feature data from pro_name_dir file, calculates the relative position score for each position in the feature data, and writes the scores to a new file specified by Feature_path"
      ],
      "metadata": {
        "id": "rI7CDZiVtBWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What : The code reads a protein sequence from a file, calculates the relative position score for each position in the sequence, and writes the scores to a new file specified by Feature_path.\n",
        "*   Why : This can be useful for analyzing and studying the positional properties of amino acids in a protein sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "ubXx_z0ftfwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GenerateFeature.py"
      ],
      "metadata": {
        "id": "3Mq9eBsstGLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import configparser\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from Physical_properties import F_Physical_properties\n",
        "from position_information import F_position\n",
        "\n",
        "\n",
        "# Creates getFeature function\n",
        "def getFeature(profile_path):\n",
        "\n",
        "    pro_file_ = open(profile_path) # Opens profile_path file\n",
        "    protein_name = pro_file_.readline() # Reads the first line of\n",
        "    protein_name = protein_name[1:].strip() # Reads the protein_name from index 1 and removes whitespace characters\n",
        "    pro_file_.close() # Closes pro_file\n",
        "\n",
        "    config = configparser.ConfigParser() # Creates an instance of configparser.ConfigParser()\n",
        "    config.read(\"Config.ini\", encoding='utf-8') # Reads Config.ini file\n",
        "\n",
        "\n",
        "    Result_path = config.get(\"Result\", \"Result_Path\") # Retrieves result from configuration file\n",
        "    if os.path.exists(Result_path): # Checks if Result_path exists\n",
        "        pass\n",
        "    else:\n",
        "        os.makedirs(Result_path) # If not, it creates Result_path\n",
        "\n",
        "    #1-pssm\n",
        "    Psi_Blast_Path = config.get(\"PeatureTool\", \"Psi_Blast_Path\") # Assigns Psi_Blast_Path from configuration file\n",
        "    DB_PATH = config.get(\"Database\", \"DB_PATH\") # Assigns DB_PATH from configuration file\n",
        "\n",
        "    # command1 and command2 are created to form the Psi-Blast command for generating PSSM (Position-Specific Scoring Matrix) data\n",
        "    command1 = Psi_Blast_Path+\"bin/psiblast\"+\" -query \"\n",
        "    command2 = \" -db \"+DB_PATH + \"/swissprot -evalue 0.001 -num_iterations 3 -out_ascii_pssm \"\n",
        "    #command2 = \" -db \" + DB_PATH + \" -evalue 0.001 -num_iterations 3 -out_ascii_pssm \"\n",
        "\n",
        "    # Checks if directory for storing PSSM file exists\n",
        "    if os.path.exists(Result_path+\"/pssm/\"):\n",
        "        pass\n",
        "    else: # If it doesn't exist, it creates it\n",
        "        os.makedirs(Result_path+\"/pssm/\")\n",
        "\n",
        "    # Executes the PSI-Blast command\n",
        "    os.system(command1 + profile_path + command2 + Result_path+\"/pssm/\"+protein_name+\".pssm\")\n",
        "    print(command1) # Prints command1\n",
        "    print(profile_path) # Prints profile_path\n",
        "    print(command2) # Prints command2\n",
        "    print(Result_path+\"/pssm/\"+protein_name+\".pssm\") # Prints Result_path+\"/pssm/\"+protein_name+\".pssm\"\n",
        "    #normalized pssm\n",
        "    content = np.genfromtxt(Result_path+\"/pssm/\"+protein_name+\".pssm\", skip_header=3, skip_footer=4)[:, 2:22] # Extracts PSSM values from columns 2 to 22 and skips the header and footer\n",
        "\n",
        "    # Creates new_file to store the normalized PSSM data\n",
        "    new_file = open(Result_path+\"/pssm/\"+protein_name+\".pssm\".strip(\".pssm\")+\".opssm\", 'w')\n",
        "\n",
        "    for m in range((content.shape)[0]): # Iterates over the rows of the content array\n",
        "        content_new = content[m:m + 1, :] # Creates new array by selecting only one row from the content array\n",
        "        content_new = np.array(content_new) # Converts content list to a NumPy array\n",
        "        content_new = content_new.tolist() # Coverts content_new NumPy array back to a list\n",
        "\n",
        "        for j in range(len(content_new[0])): # Interates over the elements of the first row of content_new\n",
        "            (content_new[0])[j] = 1 / (1 + math.exp(-(content_new[0])[j])) # # Applies the sigmoid function to each element of the row\n",
        "            (content_new[0])[j] = round((content_new[0])[j], 3) # Rounds each element to 3 decimal places\n",
        "            (content_new[0])[j] = str((content_new[0])[j]) # Converts each element to a string\n",
        "\n",
        "        content_new[0] = ' '.join(content_new[0]) # Joins the elements of the row into a single string and seperates them by spaces\n",
        "        new_file.writelines(content_new[0]+'\\n') # Writes the modified row as a line\n",
        "    new_file.close() # Closes the new_file\n",
        "\n",
        "    #2-psa\n",
        "    # Obtains the value of the Sann_Runner_Path from the configuration file\n",
        "    Sann_Runner_Path = config.get(\"PeatureTool\", \"Sann_Runner_Path\")\n",
        "\n",
        "    # Creates a command3 string\n",
        "    command3 = Sann_Runner_Path + \" \"+ profile_path +\" \" + Result_path+\"/psa/\"+protein_name+\".sa\"\n",
        "\n",
        "    # Checks if the directory exits\n",
        "    if os.path.exists(Result_path+\"/psa/\"):\n",
        "        pass\n",
        "    else: # If it doesn't exist, it creates it\n",
        "        os.makedirs(Result_path+\"/psa/\")\n",
        "    # Checks if Sann_Runner_Path exists\n",
        "    if os.path.exists(Sann_Runner_Path):\n",
        "        os.system(command3 + Result_path+\"psa/\"+protein_name+\".sa\") # If it exits, it executes the command\n",
        "    else:\n",
        "        print('\\n'+\"Sann is not installed correctly!\"+'\\n') # If it doesn't exists, it prints the message\n",
        "        pass\n",
        "\n",
        "    #3-Physical_properties\n",
        "    # Checks if the directory exists\n",
        "    if os.path.exists(Result_path+\"/Physical_properties/\"):\n",
        "        pass\n",
        "    else: # If it doesn't exist, it creates it\n",
        "        os.makedirs(Result_path+\"/Physical_properties/\")\n",
        "\n",
        "    # Calls the F_Physical_properties function from the Physical_properties class\n",
        "    F_Physical_properties(profile_path, Result_path+\"/Physical_properties/\"+protein_name)\n",
        "\n",
        "    #4-position\n",
        "    # Checks if the directory exists\n",
        "    if os.path.exists(Result_path+\"/position/\"):\n",
        "        pass\n",
        "    else: # If it doesn't exist, it creates it\n",
        "        os.makedirs(Result_path+\"/position/\")\n",
        "\n",
        "    # Calls the F_position function from the position_information class\n",
        "    F_position(profile_path, Result_path+\"/position/\"+protein_name+\".pos\")\n",
        "\n",
        "    # Returns the Result_path\n",
        "    return Result_path\n",
        "\n",
        "# This code reads a protein profile file and performs various operations to extract features, including generating PSSM data using PSI-Blast, normalizing the PSSM values, running the SANN program for PSA data, calculating physical properties using a custom function, and obtaining position information using another custom function. Then stores the results to Result_path directory."
      ],
      "metadata": {
        "id": "FyYT5A8xtGmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What & Why : The 'getFeature' function reads a protein profile file, generates PSSM data using Psi-Blast, normalizes the PSSM values, runs the SANN Runner program for PSA data, calculates physical properties, and extracts position information. It stores the generated features in specific directories under the 'Result_path'"
      ],
      "metadata": {
        "id": "pD3XzTfhtoCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataProcess.py"
      ],
      "metadata": {
        "id": "aEjRcn5mtLXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import configparser\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# set_seed function sets the seed for random number generation in various libraries\n",
        "def set_seed(seed=1):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "set_seed()\n",
        "\n",
        "\n",
        "config = configparser.ConfigParser() # Creates an object of configparser.ConfigParser()\n",
        "config.read(\"Config.ini\", encoding='utf-8') # Reads the configuration file (Config.ini)\n",
        "\n",
        "\n",
        "\n",
        "# ***************************************************Train************************************************************\n",
        "# Creates Dataprocess class that inherits from the torch.utils.data.Dataset\n",
        "class Dataprocess(Dataset):\n",
        "    def __init__(self, pro_name_path, pssm_path, psa_path, Physical_properties_path, position_path, win_size):\n",
        "        super(Dataprocess, self).__init__() # Calls the parent class torch.utils.data.Dataset\n",
        "        self.pro_name_path = pro_name_path # Assigns pro_name_path\n",
        "        self.pssm_path = pssm_path # Assigns pssm_path\n",
        "        self.psa_path = psa_path # Assigns psa_path\n",
        "        self.Physical_properties_path = Physical_properties_path # Assigns Physical_properties_path\n",
        "        self.position_path = position_path # Assigns position_path\n",
        "        self.win_size = win_size # Assigns window size\n",
        "        self.stride = win_size // 2 # Assigns stride\n",
        "        self.pro_list = os.listdir(pro_name_path) # Obtains pro_list by lisiting the files in the pro_name_path directory\n",
        "\n",
        "\n",
        "        self.allresidues = self.GetAllResidues() # Calls GetAllResidue method and assigns its returned value to the allresidues\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.allresidues) # Returns the length of allresidues list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        feature, label, residue_num = self.allresidues[index] # Assigns the value of feature, label, and residue_num for the given index\n",
        "        return feature, label, residue_num # Returns feature, label, and residue_num for the given index\n",
        "\n",
        "    # Creates GetAllResidues method to process the data for each residue in the dataset and returns a list of tuples\n",
        "    def GetAllResidues(self):\n",
        "        all_residues = [] # Intializes an empty list to store the processed data\n",
        "        num = 0 # Intializes a variable to keep track of the residue number\n",
        "\n",
        "        for index in range(len(self.pro_list)): # Iterates over the idices of the pro_list (List of Protein names)\n",
        "            pro_name = self.pro_list[index] # Extracts the protein name at the given index\n",
        "            pro_name = pro_name[:-6] # Removes the last 6 characters from it\n",
        "\n",
        "            # pssm\n",
        "            # Builds the path to the PSSM file\n",
        "            pssm_name_path = os.path.join(self.pssm_path, pro_name + '.opssm')\n",
        "            # Loads the data from the PSSM file and selects first 20 columns of the loaded data, and assigns it to the pssm variable\n",
        "            pssm = np.genfromtxt(pssm_name_path, skip_footer=0, skip_header=0)[:, :20]\n",
        "            # print(pssm.shape)\n",
        "            # Calculates the dimensions of the pssm array\n",
        "            pro_length, pssm_dim = pssm.shape\n",
        "            # Cretes padding array with zeros\n",
        "            pssm_padding = np.zeros((self.stride, pssm_dim))\n",
        "            # Concatenates the padding array with the pssm array along with axis 0\n",
        "            fea_pssm = np.append(pssm_padding, pssm, axis=0)\n",
        "            # Concatenates the pssm array with features array along with axis 0\n",
        "            fea_pssm = np.append(fea_pssm, pssm_padding, axis=0)\n",
        "\n",
        "            # psa\n",
        "            # Builds the path to the PSA file\n",
        "            psa_name_path = os.path.join(self.psa_path, pro_name + '.sa')\n",
        "            # Loads the data from PSA file and selects columns from 3 to 6 of the loaded data, and assigns it to the psa variable\n",
        "            psa = np.genfromtxt(psa_name_path, skip_footer=0, skip_header=0)[:, 3:6]\n",
        "            # Calculates the dimensions of the psa array\n",
        "            pro_length, psa_dim = psa.shape\n",
        "            # Creates a padding array with zeros\n",
        "            psa_padding = np.zeros((self.stride, psa_dim))\n",
        "            # Concatenates the padding array with psa array along with axis 0\n",
        "            fea_psa = np.append(psa_padding, psa, axis=0)\n",
        "            # Concatenates the psa array with features array along with axis 0\n",
        "            fea_psa = np.append(fea_psa, psa_padding, axis=0)\n",
        "\n",
        "            # Physical_properties (PP)\n",
        "            # Builds the path for the PP file\n",
        "            Physical_properties_name_path = os.path.join(self.Physical_properties_path, pro_name + '.pp')\n",
        "            # Loads the data from PP file and assigns it to the pp variable\n",
        "            Physical_properties = np.genfromtxt(Physical_properties_name_path, skip_footer=0, skip_header=0)\n",
        "            # Calculates the dimensions of the pp array\n",
        "            pro_length, Physical_properties_dim = Physical_properties.shape\n",
        "            # Creates a padding array with zeros\n",
        "            Physical_properties_padding = np.zeros((self.stride, Physical_properties_dim))\n",
        "            # Concatenates the padding array with pp array along with axis 0\n",
        "            fea_Physical_properties = np.append(Physical_properties_padding, Physical_properties, axis=0)\n",
        "            # Concatenates the pp array with features array along with axis 0\n",
        "            fea_Physical_properties = np.append(fea_Physical_properties, Physical_properties_padding, axis=0)\n",
        "\n",
        "            # position\n",
        "            # Builds the path for the Position file\n",
        "            position_name_path = os.path.join(self.position_path, pro_name + '.pos')\n",
        "            # Loads the data from Position file and assigns it to position variable\n",
        "            position = np.genfromtxt(position_name_path, skip_footer=0, skip_header=0)\n",
        "            # Reshapes the position array\n",
        "            position = position.reshape(pro_length, 1)\n",
        "            # Calculates the dimensions of the position array\n",
        "            pro_length, position_dim = position.shape\n",
        "            # Creates a padding array with zeros\n",
        "            position_padding = np.zeros((self.stride, position_dim))\n",
        "            # Concatenates the padding array with position array alon with axis 0\n",
        "            fea_position = np.append(position_padding, position, axis=0)\n",
        "            # Concatenates the position array with features array along with axis 0\n",
        "            fea_position = np.append(fea_position, position_padding, axis=0)\n",
        "\n",
        "            # Converts the features arrays (fea_pssm, fea_psa, fea_Physical_properties, fea_position) to torch.FloatTensor object\n",
        "            fea_pssm = torch.FloatTensor(fea_pssm)\n",
        "            fea_psa = torch.FloatTensor(fea_psa)\n",
        "            fea_Physical_properties = torch.FloatTensor(fea_Physical_properties)\n",
        "            fea_position = torch.FloatTensor(fea_position)\n",
        "\n",
        "            #feature_padding\n",
        "            # Create padding arrays (feature_padding, feature_padding_pssm, feature_padding_psa, feature_padding_position, feature_padding_Physical_properties) with zeros of appropriate shapes to be used for padding the features and converts them to torch.FloatTensor object\n",
        "            feature_padding = np.zeros((2*self.stride+pro_length, Physical_properties_dim))\n",
        "            feature_padding = torch.FloatTensor(feature_padding)\n",
        "\n",
        "\n",
        "            feature_padding_pssm = np.zeros((2*self.stride+pro_length, pssm_dim))\n",
        "            feature_padding_pssm = torch.FloatTensor(feature_padding_pssm)\n",
        "\n",
        "            feature_padding_psa = np.zeros((2 * self.stride + pro_length, psa_dim))\n",
        "            feature_padding_psa = torch.FloatTensor(feature_padding_psa)\n",
        "\n",
        "            feature_padding_position = np.zeros((2 * self.stride + pro_length, position_dim))\n",
        "            feature_padding_position = torch.FloatTensor(feature_padding_position)\n",
        "\n",
        "            feature_padding_Physical_properties = np.zeros((2 * self.stride + pro_length, Physical_properties_dim))\n",
        "            feature_padding_Physical_properties = torch.FloatTensor(feature_padding_Physical_properties)\n",
        "\n",
        "            #new_feature = torch.cat((fea_pssm, fea_psa), 1)\n",
        "            #new_feature = torch.cat((new_feature, fea_Physical_properties), 1)\n",
        "            #new_feature = torch.cat((new_feature, feature_padding_position), 1)\n",
        "\n",
        "            # Concatenate the feature arrays (fea_pssm, fea_psa, fea_Physical_properties, fea_position) along the appropriate axis to create the new_feature array\n",
        "            new_feature = torch.cat((fea_pssm, fea_psa), 1)\n",
        "            new_feature = torch.cat((new_feature, fea_Physical_properties), 1)\n",
        "            new_feature = torch.cat((new_feature, fea_position), 1)\n",
        "\n",
        "            # Opens FASTA file corresponding to the protein and read the label information\n",
        "            file = open(os.path.join(self.pro_name_path, pro_name+\".fasta\"))\n",
        "            label = file.readline() # Reads the first line\n",
        "            label = file.readline() # Reads the second line\n",
        "            label = file.readline() # Reads the third line\n",
        "            file.close() # Close the FASTA file\n",
        "            label = list(label.strip()) # Remove the whitespace characters\n",
        "            label = list(map(int, label)) # Converts each character from label list into integer\n",
        "            label = np.array(label) # Converts list of integers to a NumPy array\n",
        "            label = label.reshape(len(label), 1) # Converts the shape of array to have one column and a number of rows equal to the length of the array\n",
        "            # 定义滑动窗口\n",
        "\n",
        "            # Creates an array with zeros\n",
        "            PadDing = np.zeros((position_dim+pssm_dim+psa_dim+Physical_properties_dim, 15-self.stride))\n",
        "            # Convertes the NumPy array to a PyTorch array\n",
        "            PadDing = torch.FloatTensor(PadDing)\n",
        "\n",
        "            # The for loop iterates over a range of indices to process each residue\n",
        "            for i in range(self.stride, pro_length + self.stride):\n",
        "                num += 1 # Increments the num by 1\n",
        "                residue_fea = np.transpose(new_feature[i - self.stride:i + self.stride + 1]) # Extracts a subarray and rearranges the rows and columns of the subarray (Transpose the dimensions of the subarray)\n",
        "                residue_fea = torch.cat((PadDing, residue_fea, PadDing), 1) # Concatenates the subarray on both sides along with axis 1. This effectively adds PadDing as padding columns at the beginning and end of residue_fea\n",
        "                all_residues.append((residue_fea, label[i - self.stride], num)) # (residue_fea, label[i - self.stride], num) is appended to the all_residues list as a tuple\n",
        "        np.random.shuffle(all_residues) # Randomly shuffles the order of elements in all_residues list\n",
        "        return all_residues # Returns all_residues"
      ],
      "metadata": {
        "id": "MpTtYc7_tLfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What & Why : The code takes a protein profile file as input and performs various operations to extract features such as PSSM data, normalized PSSM values, PSA data, physical properties, and position information. The extracted features are then stored in a specified directory, which is returned as the result"
      ],
      "metadata": {
        "id": "uZlGhCPJtpdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DESNET.py"
      ],
      "metadata": {
        "id": "A7hXRzqqtTGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vv import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=5):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class Residual_Block(nn.Module):\n",
        "    def __init__(self, i_channel, o_channel, stride=1, downsample=None):\n",
        "        super(Residual_Block, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=i_channel, out_channels=o_channel, kernel_size=3, stride=stride, padding=1,\n",
        "                               bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(o_channel)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=o_channel, out_channels=o_channel, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(o_channel)\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "##############################################################\n",
        "# ResNet\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.SElayer = SELayer(16)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[0], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[1], 2)\n",
        "        self.layer4 = self.make_layer(block, 96, layers[2], 2)   #add0\n",
        "        self.layer5 = self.make_layer(block, 128, layers[3], 2)  #add1\n",
        "        #self.layer6 = self.make_layer(block, 512, layers[3], 2)  # add2\n",
        "        self.avg_pool = nn.AvgPool2d((2,2))\n",
        "        #self.fc = nn.Linear(64, num_classes)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):  # blocks=layers,the number of residual block\n",
        "        downsample = None\n",
        "\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                #nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "                nn.Conv2d(self.in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)  # add all of the residual block\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.SElayer(out)\n",
        "        #print(out.shape)\n",
        "        out = self.bn(out)\n",
        "        #print(out.shape)\n",
        "        #out = SELayer(out)\n",
        "        out = self.relu(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer1(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer2(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer3(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer4(out)     #add0\n",
        "        #print(out.shape)\n",
        "        out = self.layer5(out)     #add1\n",
        "        #out = self.layer6(out)     #add2\n",
        "        #print(out.shape)\n",
        "        out = self.avg_pool(out)\n",
        "        #print(out.shape)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "#model = ResNet(Residual_Block, [3, 3, 3, 3])\n",
        "#x = torch.rand(2,1,39,31)\n",
        "#f = model(x)\n",
        "#print(f)"
      ],
      "metadata": {
        "id": "MJkn9bUTtTOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What & Why : The code defines a ResNet model for image classification. It consists of residual blocks and includes a Squeeze-and-Excitation layer to capture channel-wise dependencies."
      ],
      "metadata": {
        "id": "rrP3bJ0rtqeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D-PPIsite.py"
      ],
      "metadata": {
        "id": "PKuCBlsqtW0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from DataProcess import Dataprocess\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "import os\n",
        "from DESNET import Residual_Block\n",
        "from DESNET import ResNet\n",
        "import sys\n",
        "from GenerateFeature import getFeature\n",
        "import configparser\n",
        "\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read(\"Config.ini\", encoding='utf-8')\n",
        "\n",
        "\n",
        "def run(path):\n",
        "    return path\n",
        "\n",
        "profile_path = run(sys.argv[1])\n",
        "\n",
        "protein_file_path = getFeature(profile_path)\n",
        "\n",
        "pro_file_ = open(profile_path)\n",
        "protein_name = pro_file_.readline()\n",
        "protein_name = protein_name[1:].strip()\n",
        "pro_file_.close()\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "\n",
        "model_num = 18\n",
        "thred = 0.75\n",
        "\n",
        "def Compute_data(validation_loader, savemodel):\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    file_out = open(protein_file_path + 'PredictResult', 'w')\n",
        "    file_lab = open(protein_file_path + 'Lable', 'w')\n",
        "\n",
        "    for i, data in enumerate(validation_loader):\n",
        "        features, labels, _ = data\n",
        "        features = Variable(features)\n",
        "        labels = Variable(labels.float())\n",
        "        features = torch.FloatTensor(features).to(device)\n",
        "        labels = torch.FloatTensor(labels).to(device)\n",
        "        features = torch.unsqueeze(features, 1)\n",
        "        output = 0\n",
        "        for modelnum in range(model_num):\n",
        "            model1 = ResNet(Residual_Block, [2, 2, 2, 2]).to(device)\n",
        "            model1.load_state_dict(torch.load(savemodel + 'resnet'+str(modelnum+1), map_location='cpu'), strict=True)\n",
        "            model1.eval()\n",
        "            out1 = model1(features)\n",
        "            output += out1\n",
        "        output = output/model_num\n",
        "\n",
        "\n",
        "        for ii in range(len(output)):\n",
        "            out = output[ii].data\n",
        "            labe = labels[ii].data\n",
        "            out = round(float(out), 3)\n",
        "            labe = float(labe)\n",
        "\n",
        "            out = str(out)\n",
        "            labe = str(labe)\n",
        "\n",
        "            file_out.write(out + '\\n')\n",
        "            file_lab.write(labe + '\\n')\n",
        "\n",
        "\n",
        "        for index in range(len(labels)):\n",
        "            if output[index] < thred:\n",
        "                if labels[index] == 0:\n",
        "                    TN += 1\n",
        "                else:\n",
        "                    FN += 1\n",
        "            elif output[index] >= thred:\n",
        "                if labels[index] == 1:\n",
        "                    TP += 1\n",
        "                else:\n",
        "                    FP += 1\n",
        "\n",
        "    Acc = (TP+TN)/(TP+FN+FP+TN)\n",
        "    Acc = round(Acc, 3)\n",
        "    if (TP+FN)!=0:\n",
        "        Sen = TP/(TP+FN)\n",
        "        Sen = round(Sen, 3)\n",
        "    else:\n",
        "        Sen=\"none\"\n",
        "    if (TN+FP)!=0:\n",
        "        Spe = TN/(TN+FP)\n",
        "        Spe = round(Spe, 3)\n",
        "    else:\n",
        "        Spe = \"none\"\n",
        "    if (TP+FP)!=0:\n",
        "        Pre = TP/(TP+FP)\n",
        "        Pre = round(Pre, 3)\n",
        "    else:\n",
        "        Pre = \"none\"\n",
        "    if ((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) ** 0.5!=0:\n",
        "        MCC = (TP * TN - FN * FP) / (((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) ** 0.5)\n",
        "        MCC = round(MCC, 3)\n",
        "    else:\n",
        "        MCC = \"none\"\n",
        "    print('ACC=', Acc,\" \", 'SEN=',Sen,\" \", 'SPE=',Spe,\" \", 'PRE=', Pre, \" \",'MCC=', MCC)\n",
        "    print(\"TP=\",TP, \" \",\"TN=\", TN,\" \", \"FP=\", FP,\" \", \"FN=\", FN)\n",
        "    file_out.close()\n",
        "    file_lab.close()\n",
        "    return TP, TN, FP, FN\n",
        "\n",
        "pro_name = profile_path.strip(protein_name+\".fasta\")\n",
        "\n",
        "print(profile_path)\n",
        "print(protein_name)\n",
        "print(pro_name+\"!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "feature_path = config.get(\"Result\", \"Result_Path\")\n",
        "pssm_path = feature_path+\"pssm/\"\n",
        "psa_path = feature_path+\"psa/\"\n",
        "Physical_properties_path = feature_path+\"Physical_properties/\"\n",
        "position_path = feature_path+\"position/\"\n",
        "savemodel =\"models/\"\n",
        "\n",
        "win_size = 17\n",
        "batch_size = 100\n",
        "\n",
        "Get_Data_Validation = Dataprocess(pro_name, pssm_path, psa_path, Physical_properties_path,position_path, win_size)\n",
        "\n",
        "validation_loader = DataLoader(dataset=Get_Data_Validation, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "result = Compute_data(validation_loader,savemodel)\n",
        "\n",
        "#G:/ywjcodefile_msa/xxxxxxxx/ProteinCase/2dvwA"
      ],
      "metadata": {
        "id": "c7ZsxuxltW9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   What & Why : The code reads protein profile data, generates features, loads pre-trained ResNet models, performs classification on validation data, evaluates model performance, and writes the results to files. It provides insights into the accuracy and effectiveness of the trained protein classification model."
      ],
      "metadata": {
        "id": "zUnB_mTNtsAy"
      }
    }
  ]
}